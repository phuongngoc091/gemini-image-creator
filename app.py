import streamlit as st
import google.generativeai as genai
from PIL import Image
import json

# --- C·∫•u h√¨nh trang v√† ti√™u ƒë·ªÅ ---
st.set_page_config(layout="wide", page_title="Tr·ª£ l√Ω S√°ng t·∫°o Video AI")
st.title("üé¨ Tr·ª£ l√Ω S√°ng t·∫°o Video AI")
st.caption("T·∫°o k·ªãch b·∫£n video chi ti·∫øt t·ª´ √Ω t∆∞·ªüng ƒë∆°n gi·∫£n c·ªßa b·∫°n.")

# --- C√ÅC KHU√îN M·∫™U PROMPT (TEMPLATES) ---

# Khu√¥n m·∫´u cho Option 1 (T·∫£i ·∫£nh l√™n)
IMAGE_TO_VIDEO_TEMPLATE = """
Initial Frame: Use the provided image of {subject_description}.

Animation:
- Movement: Animate the subject to {core_action}.
- Speech: {dialogue_section}
- Gesture: While speaking or moving, the subject makes a natural gesture, such as {gesture}.
- Continued Movement: After the main action, the subject continues their action naturally to complete the scene.

Visual Effects: Maintain the atmosphere, lighting, and environmental effects from the original image. Ensure effects like {visual_effects} are animated and consistent throughout the 8-second clip.

Audio: {audio_section}
"""

# Khu√¥n m·∫´u cho Option 2 (Ch·ªâ c√≥ √Ω t∆∞·ªüng)
TEXT_TO_VIDEO_TEMPLATE = """
Scene Description: A cinematic, ultra-detailed, 8k, photorealistic shot of {subject_description}. The setting is {setting_description}. The lighting is dramatic and fits the mood.

Animation:
- Movement: Animate the subject to {core_action}.
- Speech: {dialogue_section}
- Gesture: While speaking or moving, the subject makes a natural gesture, such as {gesture}.
- Continued Movement: After the main action, the subject continues their action naturally to complete the scene.

Visual Effects: The atmosphere is {mood}. Create realistic environmental effects like {visual_effects} for the 8-second clip.

Audio: {audio_section}
"""

# --- SI√äU PROMPT D√ÄNH CHO "BI√äN K·ªäCH AI" (PHI√äN B·∫¢N N√ÇNG C·∫§P) ---
META_PROMPT_FOR_GEMINI = """
You are an expert creative director and scriptwriter for a cutting-edge text-to-video AI model. Your task is to transform a user's simple idea (in Vietnamese) into a rich, detailed, and technically precise cinematic prompt in English.

**Analyze the user's idea by following these steps:**
1.  **Deconstruct the core elements:** Identify the main subject, the core action, and the setting from the user's idea.
2.  **Envision the scene:** Based on the core elements, creatively imagine the mood, lighting, and cinematic style. Think like a director. What would make this scene powerful?
3.  **Process the dialogue:**
    - If dialogue exists, rewrite it to be impactful and concise (under 8 seconds). Keep it in the original Vietnamese.
    - If no dialogue exists, leave the dialogue field empty.
4.  **Translate and Structure:** Translate all descriptive elements into fluent, evocative English. Keep the dialogue in Vietnamese. Structure the final output as a single, clean JSON object.

**Here is an example of the quality I expect:**
-   **User's simple idea (Vietnamese):** "c√¥ g√°i ƒëi tr√™n C·∫ßu V√†ng c√≥ tuy·∫øt r∆°i v√† n√≥i 'Ch√†o m·ªçi ng∆∞·ªùi! Tuy·∫øt r∆°i ƒë·∫πp kh√¥ng?'"
-   **Your high-quality JSON output:**
    {
        "subject_description": "a young Vietnamese woman with a graceful walk, wearing a warm, elegant coat",
        "core_action": "walking forward along the iconic Golden Bridge in Da Nang, moving directly towards the camera",
        "setting_description": "the Golden Bridge in Da Nang, Vietnam, uniquely covered in a gentle, magical snowfall",
        "dialogue": "Ch√†o m·ªçi ng∆∞·ªùi! Tuy·∫øt r∆°i ·ªü C·∫ßu V√†ng, ƒë·∫πp si√™u th·ª±c lu√¥n!",
        "tone": "friendly and slightly amazed",
        "language": "Vietnamese",
        "voice_type": "a warm, gentle female voice",
        "gesture": "raising a hand to catch a falling snowflake, with a sense of wonder",
        "visual_effects": "realistic falling snow, soft and ambient light reflecting off the golden structure",
        "mood": "magical, serene, and wondrous"
    }

**Now, analyze the following user's idea and generate the JSON output based on the same high standard.**

User's Idea: "{user_idea}"
"""

# --- C·∫•u h√¨nh API Key ·ªü thanh b√™n (sidebar) ---
with st.sidebar:
    st.header("C·∫•u h√¨nh")
    try:
        google_api_key = st.secrets["GOOGLE_API_KEY"]
        st.success("ƒê√£ t√¨m th·∫•y API Key!", icon="‚úÖ")
    except (FileNotFoundError, KeyError):
        st.warning("Kh√¥ng t√¨m th·∫•y API Key trong Secrets. Vui l√≤ng nh·∫≠p th·ªß c√¥ng.", icon="‚ö†Ô∏è")
        google_api_key = st.text_input("Nh·∫≠p Google API Key c·ªßa b·∫°n:", type="password")

if not google_api_key:
    st.error("Vui l√≤ng nh·∫≠p API Key c·ªßa b·∫°n ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

try:
    genai.configure(api_key=google_api_key)
    gemini_model = genai.GenerativeModel(model_name="gemini-2.5-flash")
except Exception as e:
    st.error(f"L·ªói c·∫•u h√¨nh API Key: {e}")
    st.stop()

# --- Giao di·ªán ·ª©ng d·ª•ng ---
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("üñºÔ∏è ƒê·∫ßu v√†o")
    uploaded_file = st.file_uploader(
        "T·∫£i ·∫£nh l√™n (cho t√πy ch·ªçn ·∫¢nh -> Video)",
        type=["png", "jpg", "jpeg"]
    )
    if uploaded_file is not None:
        image_to_display = Image.open(uploaded_file)
        st.image(image_to_display, caption="Khung h√¨nh kh·ªüi ƒë·∫ßu", use_column_width=True)

with col2:
    st.subheader("üí° √ù t∆∞·ªüng c·ªßa b·∫°n")
    with st.form("prompt_form"):
        user_idea = st.text_area(
            "Nh·∫≠p √Ω t∆∞·ªüng video b·∫±ng ti·∫øng Vi·ªát:",
            height=200,
            placeholder="V√≠ d·ª•: m·ªôt c√¥ g√°i ƒëi tr√™n C·∫ßu V√†ng c√≥ tuy·∫øt r∆°i v√† n√≥i 'Ch√†o m·ªçi ng∆∞·ªùi! Tuy·∫øt r∆°i ƒë·∫πp kh√¥ng?'"
        )
        submitted = st.form_submit_button("T·∫°o k·ªãch b·∫£n Prompt")

    if submitted:
        if not user_idea:
            st.warning("Vui l√≤ng nh·∫≠p √Ω t∆∞·ªüng c·ªßa b·∫°n.")
        else:
            with st.spinner("ü§ñ Bi√™n k·ªãch AI ƒëang ph√¢n t√≠ch v√† s√°ng t·∫°o..."):
                try:
                    # B∆∞·ªõc 1: G·ª≠i y√™u c·∫ßu ph√¢n t√≠ch ƒë·∫øn Gemini
                    request_for_gemini = META_PROMPT_FOR_GEMINI.format(user_idea=user_idea)
                    response = gemini_model.generate_content(request_for_gemini)
                    
                    # Tr√≠ch xu·∫•t v√† l√†m s·∫°ch JSON t·ª´ ph·∫£n h·ªìi
                    response_text = response.text.replace("```json", "").replace("```", "").strip()
                    extracted_data = json.loads(response_text)

                    # B∆∞·ªõc 2: L·∫Øp r√°p prompt cu·ªëi c√πng
                    final_prompt = ""
                    if uploaded_file is not None:
                        # Option 1: C√≥ ·∫£nh
                        template = IMAGE_TO_VIDEO_TEMPLATE
                    else:
                        # Option 2: Ch·ªâ c√≥ text
                        template = TEXT_TO_VIDEO_TEMPLATE
                    
                    # X·ª≠ l√Ω ph·∫ßn l·ªùi tho·∫°i v√† √¢m thanh ƒë·ªÉ c√≥ th·ªÉ ·∫©n ƒëi n·∫øu kh√¥ng c√≥
                    if extracted_data.get("dialogue"):
                        extracted_data['dialogue_section'] = f"Animate the subject's mouth to synchronize with the speech: \"{extracted_data['dialogue']}\"."
                        extracted_data['audio_section'] = f"Generate natural-sounding {extracted_data['language']} speech for the dialogue, spoken by a {extracted_data['voice_type']} with a {extracted_data['tone']} tone."
                    else:
                        extracted_data['dialogue_section'] = "No dialogue."
                        extracted_data['audio_section'] = "No speech audio, only ambient sounds matching the scene."

                    # ƒêo·∫°n code m·ªõi linh ho·∫°t h∆°n
                    try:
                        final_prompt = template.format(
                            subject_description=extracted_data.get('subject_description', 'a person in a scene'),
                            core_action=extracted_data.get('core_action', 'performing an action'),
                            setting_description=extracted_data.get('setting_description', 'an interesting setting'),
                            dialogue_section=extracted_data.get('dialogue_section', 'No dialogue.'),
                            audio_section=extracted_data.get('audio_section', 'No speech audio.'),
                            gesture=extracted_data.get('gesture', 'a natural gesture'),
                            visual_effects=extracted_data.get('visual_effects', 'cinematic effects'),
                            mood=extracted_data.get('mood', 'an interesting mood')
                        )
                    except KeyError as e:
                        st.error(f"L·ªói: AI ƒë√£ kh√¥ng tr·∫£ v·ªÅ ƒë·ªß c√°c tr∆∞·ªùng d·ªØ li·ªáu c·∫ßn thi·∫øt. Vui l√≤ng th·ª≠ l·∫°i. Tr∆∞·ªùng b·ªã thi·∫øu: {e}")
                        st.stop() # D·ª´ng th·ª±c thi n·∫øu c√≥ l·ªói nghi√™m tr·ªçng
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    st.divider()
                    st.subheader("üé¨ K·ªãch b·∫£n Prompt chi ti·∫øt (Ti·∫øng Anh)")
                    st.info("ƒê√¢y l√† prompt ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ g·ª≠i ƒë·∫øn AI t·∫°o video (nh∆∞ Veo).")
                    st.text_area("Prompt cu·ªëi c√πng:", value=final_prompt, height=400)

                except json.JSONDecodeError:
                    st.error("L·ªói: AI kh√¥ng tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng JSON h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i v·ªõi √Ω t∆∞·ªüng r√µ r√†ng h∆°n.")
                    st.write("D·ªØ li·ªáu th√¥ t·ª´ AI:", response_text)
                except Exception as e:
                    st.error(f"ƒê√£ x·∫£y ra l·ªói kh√¥ng mong mu·ªën: {e}")
