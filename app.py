import streamlit as st
import google.generativeai as genai
from PIL import Image
import json

# --- C·∫•u h√¨nh trang v√† ti√™u ƒë·ªÅ ---
st.set_page_config(layout="wide", page_title="Tr·ª£ l√Ω S√°ng t·∫°o Video AI")
st.title("üé¨ Tr·ª£ l√Ω S√°ng t·∫°o Video AI")
st.caption("T·∫°o k·ªãch b·∫£n video chi ti·∫øt t·ª´ √Ω t∆∞·ªüng ƒë∆°n gi·∫£n c·ªßa b·∫°n.")

# --- C√ÅC KHU√îN M·∫™U PROMPT (TEMPLATES) ---
IMAGE_TO_VIDEO_TEMPLATE = """
Initial Frame: Use the provided image of {subject_description}.
Animation: Animate the subject to {core_action}.
Speech: {dialogue_section}
Visual Effects: Maintain the original atmosphere. Animate effects like {visual_effects}.
Audio: {audio_section}
"""
TEXT_TO_VIDEO_TEMPLATE = """
Scene Description: A cinematic, 8k, photorealistic shot of {subject_description} in {setting_description}. The mood is {mood}.
Animation: Animate the subject to {core_action}.
Speech: {dialogue_section}
Visual Effects: Create realistic effects like {visual_effects}.
Audio: {audio_section}
"""

# --- SI√äU PROMPT D√ÄNH CHO "BI√äN K·ªäCH AI" (PHI√äN B·∫¢N ƒê∆†N GI·∫¢N H√ìA) ---
META_PROMPT_FOR_GEMINI = """
Analyze the user's Vietnamese video idea. Extract key information and translate it to English.
Rewrite the dialogue in Vietnamese to be concise (under 8 seconds).
Output a clean JSON object.

User Idea: "{user_idea}"

JSON fields:
- "subject_description": (Translate to English) The main subject.
- "core_action": (Translate to English) The main action.
- "setting_description": (Translate to English) The location.
- "dialogue": (Keep and rewrite in Vietnamese) The speech.
- "mood": (Translate to English) The feeling of the scene.
- "visual_effects": (Translate to English) Visual effects.
- "voice_type": (Translate to English) e.g., 'a warm female voice'.
"""

# --- C·∫•u h√¨nh API Key ·ªü thanh b√™n (sidebar) ---
with st.sidebar:
    st.header("C·∫•u h√¨nh")
    try:
        google_api_key = st.secrets["GOOGLE_API_KEY"]
        st.success("ƒê√£ t√¨m th·∫•y API Key!", icon="‚úÖ")
    except (FileNotFoundError, KeyError):
        st.warning("Kh√¥ng t√¨m th·∫•y API Key trong Secrets. Vui l√≤ng nh·∫≠p th·ªß c√¥ng.", icon="‚ö†Ô∏è")
        google_api_key = st.text_input("Nh·∫≠p Google API Key c·ªßa b·∫°n:", type="password")

if not google_api_key:
    st.error("Vui l√≤ng nh·∫≠p API Key c·ªßa b·∫°n ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

try:
    genai.configure(api_key=google_api_key)
    gemini_model = genai.GenerativeModel(model_name="gemini-2.5-flash")
except Exception as e:
    st.error(f"L·ªói c·∫•u h√¨nh API Key: {e}")
    st.stop()

# --- Giao di·ªán ·ª©ng d·ª•ng ---
col1, col2 = st.columns([1, 2])
with col1:
    st.subheader("üñºÔ∏è ƒê·∫ßu v√†o")
    uploaded_file = st.file_uploader("T·∫£i ·∫£nh l√™n (cho t√πy ch·ªçn ·∫¢nh -> Video)", type=["png", "jpg", "jpeg"])
    if uploaded_file:
        st.image(Image.open(uploaded_file), caption="Khung h√¨nh kh·ªüi ƒë·∫ßu", use_column_width=True)

with col2:
    st.subheader("üí° √ù t∆∞·ªüng c·ªßa b·∫°n")
    with st.form("prompt_form"):
        user_idea = st.text_area("Nh·∫≠p √Ω t∆∞·ªüng video b·∫±ng ti·∫øng Vi·ªát:", height=200, placeholder="V√≠ d·ª•: m·ªôt c√¥ g√°i ƒëi tr√™n C·∫ßu V√†ng c√≥ tuy·∫øt r∆°i v√† n√≥i 'Ch√†o m·ªçi ng∆∞·ªùi! Tuy·∫øt r∆°i ƒë·∫πp kh√¥ng?'")
        submitted = st.form_submit_button("T·∫°o k·ªãch b·∫£n Prompt")

    if submitted and user_idea:
        with st.spinner("ü§ñ Bi√™n k·ªãch AI ƒëang ph√¢n t√≠ch..."):
            try:
                # B∆∞·ªõc 1: G·ªçi AI ƒë·ªÉ tr√≠ch xu·∫•t JSON
                request_for_gemini = META_PROMPT_FOR_GEMINI.format(user_idea=user_idea)
                response = gemini_model.generate_content(request_for_gemini)
                response_text = response.text.replace("```json", "").replace("```", "").strip()
                extracted_data = json.loads(response_text)

                # B∆∞·ªõc 2: G√°n gi√° tr·ªã an to√†n
                prompt_data = {
                    'subject_description': extracted_data.get('subject_description', 'a scene'),
                    'core_action': extracted_data.get('core_action', 'an action'),
                    'setting_description': extracted_data.get('setting_description', 'a location'),
                    'dialogue': extracted_data.get('dialogue', ''),
                    'mood': extracted_data.get('mood', 'neutral'),
                    'visual_effects': extracted_data.get('visual_effects', 'none'),
                    'voice_type': extracted_data.get('voice_type', 'a voice')
                }

                # X·ª≠ l√Ω ph·∫ßn l·ªùi tho·∫°i
                if prompt_data['dialogue']:
                    prompt_data['dialogue_section'] = f"Animate the subject's mouth to synchronize with the speech: \"{prompt_data['dialogue']}\"."
                    prompt_data['audio_section'] = f"Generate natural-sounding Vietnamese speech, spoken by {prompt_data['voice_type']}."
                else:
                    prompt_data['dialogue_section'] = "No dialogue."
                    prompt_data['audio_section'] = "No speech audio, only ambient sounds."

                # B∆∞·ªõc 3: L·∫Øp r√°p prompt
                template = IMAGE_TO_VIDEO_TEMPLATE if uploaded_file else TEXT_TO_VIDEO_TEMPLATE
                final_prompt = template.format(**prompt_data)

                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.divider()
                st.subheader("üé¨ K·ªãch b·∫£n Prompt chi ti·∫øt (Ti·∫øng Anh)")
                st.text_area("Prompt cu·ªëi c√πng:", value=final_prompt, height=400)

            except Exception as e:
                st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")
                st.write("D·ªØ li·ªáu th√¥ t·ª´ AI (ƒë·ªÉ g·ª° l·ªói):", response_text)

    elif submitted:
        st.warning("Vui l√≤ng nh·∫≠p √Ω t∆∞·ªüng c·ªßa b·∫°n.")
